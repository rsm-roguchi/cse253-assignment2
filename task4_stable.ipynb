{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec59beb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'flash_attn'\n",
      "flash_attn not installed, disabling Flash Attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "from stable_audio_tools.models.pretrained import get_pretrained_model\n",
    "\n",
    "model, model_config = get_pretrained_model(\"stabilityai/stable-audio-open-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f01e14b-38ce-4419-8942-2f54f816faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/stable-audio-tools\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a08fe1-b112-4d0f-b922-94d7506a9db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2428f9e4-3b28-4c5c-b62c-b3050c1adfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Encoding and saving pre-encoded latent segments...\n",
      "✅ Done. Saved 428 pre-encoded .npy segments to: /workspace/data3_preencoded_overlap\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# Ensure model has pretransform encoder\n",
    "assert hasattr(model, \"pretransform\") and model.pretransform is not None, \"Your model must have a .pretransform encoder\"\n",
    "model.pretransform.to(\"cuda\").eval()\n",
    "\n",
    "# Config\n",
    "AUDIO_DIR = Path(\"/workspace/data3\")\n",
    "OUTPUT_DIR = Path(\"/workspace/data3_preencoded_overlap\")\n",
    "SAMPLE_RATE = 44100\n",
    "SEGMENT_DURATION = 4.0\n",
    "SEGMENT_SAMPLES = int(SAMPLE_RATE * SEGMENT_DURATION)\n",
    "\n",
    "OVERLAP_RATIO = 0.75\n",
    "STEP_SIZE = int(SEGMENT_SAMPLES * (1 - OVERLAP_RATIO))\n",
    "\n",
    "MIN_RMS_THRESHOLD = 0.01  # Skip near-silent segments\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"🔁 Encoding and saving pre-encoded latent segments...\")\n",
    "\n",
    "def is_non_silent(segment, threshold=MIN_RMS_THRESHOLD):\n",
    "    return segment.std() > threshold\n",
    "\n",
    "total_saved = 0\n",
    "\n",
    "for file in AUDIO_DIR.glob(\"*.wav\"):\n",
    "    try:\n",
    "        audio, sr = torchaudio.load(str(file))\n",
    "\n",
    "        # Resample to match model\n",
    "        if sr != SAMPLE_RATE:\n",
    "            audio = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(audio)\n",
    "\n",
    "        # Force mono → stereo if needed\n",
    "        if audio.shape[0] == 1:\n",
    "            audio = torch.cat([audio, audio], dim=0)  # [2, T]\n",
    "        \n",
    "\n",
    "        audio_len = audio.shape[1]\n",
    "        seg_idx = 0\n",
    "\n",
    "        for start in range(0, audio_len - SEGMENT_SAMPLES + 1, STEP_SIZE):\n",
    "            segment = audio[:, start:start + SEGMENT_SAMPLES]  # [2, T]\n",
    "\n",
    "            if not is_non_silent(segment):\n",
    "                continue\n",
    "\n",
    "            segment = segment.unsqueeze(0).to(\"cuda\")  # [1, 2, T]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                latent = model.pretransform.encode(segment)  # [1, D, T']\n",
    "                latent = latent.squeeze(0).cpu().numpy()     # [D, T']\n",
    "\n",
    "            out_path = OUTPUT_DIR / f\"{file.stem}_ov{seg_idx}.npy\"\n",
    "            np.save(out_path, latent)\n",
    "\n",
    "            seg_idx += 1\n",
    "            total_saved += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file.name}: {e}\")\n",
    "\n",
    "print(f\"✅ Done. Saved {total_saved} pre-encoded .npy segments to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449e9d38-8c2c-4949-ba91-11c85d320170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 428 files\n"
     ]
    }
   ],
   "source": [
    "from stable_audio_tools.data.dataset import create_dataloader_from_config\n",
    "import json\n",
    "\n",
    "with open(\"/workspace/dataset_config.json\") as f:\n",
    "    dataset_config = json.load(f)\n",
    "\n",
    "train_loader = create_dataloader_from_config(\n",
    "    dataset_config,\n",
    "    batch_size=1,\n",
    "    sample_size=176400,\n",
    "    sample_rate=44100,\n",
    "    audio_channels=2,\n",
    "    num_workers=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6fa03ed-63cf-4f9f-a0c1-2a3590001f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de04a422-8da4-435f-aa49-dee9fa6ddf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    575\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    577\u001b[0m     ckpt_path,\n\u001b[1;32m    578\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m )\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:966\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m--> 966\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/single_device.py:77\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msetup(trainer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/single_device.py:74\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.model_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.model must be set before self.model.to()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/device_dtype_mixin.py:54\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__update_properties(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 915 (7 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m      4\u001b[0m training_wrapper \u001b[38;5;241m=\u001b[39m DiffusionCondTrainingWrapper(\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      6\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m      7\u001b[0m     pre_encoded\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     11\u001b[0m     max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1200\u001b[39m,                     \u001b[38;5;66;03m# <-- total steps to train\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     accumulate_grad_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,          \u001b[38;5;66;03m# <-- simulate larger batch\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m training_wrapper\u001b[38;5;241m.\u001b[39mexport_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/stable-audio-tools/saved/final_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/stable-audio-tools/saved/final_model_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:68\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[1;32m     67\u001b[0m     logger\u001b[38;5;241m.\u001b[39mfinalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[1;32m     70\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py:1013\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1013\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py:528\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: moving model to CPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/device_dtype_mixin.py:79\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See :meth:`torch.nn.Module.cpu`.\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__update_properties(device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1133\u001b[0m, in \u001b[0;36mModule.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 915 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1133\u001b[0m, in \u001b[0;36mModule.cpu.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from stable_audio_tools.training.diffusion import DiffusionCondTrainingWrapper\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "training_wrapper = DiffusionCondTrainingWrapper(\n",
    "    model=model,\n",
    "    lr=1e-4,\n",
    "    pre_encoded=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_steps=1200,                     # <-- total steps to train\n",
    "    accumulate_grad_batches=2,          # <-- simulate larger batch\n",
    "    precision='16-mixed',                        # <-- mixed precision (faster)\n",
    "    log_every_n_steps=600,               # <-- print loss every 10 steps\n",
    "    enable_progress_bar=True,           \n",
    "    enable_checkpointing=False,\n",
    "    val_check_interval=None,\n",
    "    strategy='auto',\n",
    "    devices=1\n",
    ")\n",
    "\n",
    "trainer.fit(training_wrapper, train_dataloaders=train_loader)\n",
    "training_wrapper.export_model(\"/workspace/stable-audio-tools/saved/final_model.pt\")\n",
    "\n",
    "with open(\"/workspace/stable-audio-tools/saved/final_model_config.json\", \"w\") as f:\n",
    "    json.dump(model_config, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c8d53b-1bea-46d0-a080-e8add4159b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConditionedDiffusionModelWrapper(\n",
       "  (model): DiTWrapper(\n",
       "    (model): DiffusionTransformer(\n",
       "      (timestep_features): FourierFeatures()\n",
       "      (to_timestep_embed): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (to_cond_embed): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=1024, bias=False)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (to_global_embed): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=1024, bias=False)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "      (transformer): ContinuousTransformer(\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x TransformerBlock(\n",
       "            (pre_norm): LayerNorm()\n",
       "            (self_attn): Attention(\n",
       "              (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (q_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "              (k_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (self_attn_scale): Identity()\n",
       "            (cross_attend_norm): LayerNorm()\n",
       "            (cross_attn): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (q_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "              (k_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (cross_attn_scale): Identity()\n",
       "            (ff_norm): LayerNorm()\n",
       "            (ff): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): GLU(\n",
       "                  (act): SiLU()\n",
       "                  (proj): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (3): Identity()\n",
       "              )\n",
       "            )\n",
       "            (ff_scale): Identity()\n",
       "          )\n",
       "        )\n",
       "        (project_in): Linear(in_features=64, out_features=1024, bias=False)\n",
       "        (project_out): Linear(in_features=1024, out_features=64, bias=False)\n",
       "        (rotary_pos_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (preprocess_conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (postprocess_conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (conditioner): MultiConditioner(\n",
       "    (conditioners): ModuleDict(\n",
       "      (prompt): T5Conditioner(\n",
       "        (proj_out): Identity()\n",
       "      )\n",
       "      (seconds_total): NumberConditioner(\n",
       "        (proj_out): Identity()\n",
       "        (embedder): NumberEmbedder(\n",
       "          (embedding): Sequential(\n",
       "            (0): LearnedPositionalEmbedding()\n",
       "            (1): Linear(in_features=257, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pretransform): AutoencoderPretransform(\n",
       "    (model): AudioAutoencoder(\n",
       "      (bottleneck): VAEBottleneck()\n",
       "      (encoder): OobleckEncoder(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv1d(2, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): EncoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (1): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): SnakeBeta()\n",
       "              (4): Conv1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "            )\n",
       "          )\n",
       "          (2): EncoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (1): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): SnakeBeta()\n",
       "              (4): Conv1d(128, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "            )\n",
       "          )\n",
       "          (3): EncoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (1): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): SnakeBeta()\n",
       "              (4): Conv1d(256, 512, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "            )\n",
       "          )\n",
       "          (4): EncoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (1): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): SnakeBeta()\n",
       "              (4): Conv1d(512, 1024, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "            )\n",
       "          )\n",
       "          (5): EncoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(1024, 1024, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (1): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(1024, 1024, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(1024, 1024, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): SnakeBeta()\n",
       "              (4): Conv1d(1024, 2048, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "            )\n",
       "          )\n",
       "          (6): SnakeBeta()\n",
       "          (7): Conv1d(2048, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (decoder): OobleckDecoder(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv1d(64, 2048, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): DecoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): SnakeBeta()\n",
       "              (1): ConvTranspose1d(2048, 1024, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(1024, 1024, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(1024, 1024, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (4): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(1024, 1024, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): DecoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): SnakeBeta()\n",
       "              (1): ConvTranspose1d(1024, 512, kernel_size=(16,), stride=(8,), padding=(4,))\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (4): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): DecoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): SnakeBeta()\n",
       "              (1): ConvTranspose1d(512, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (4): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): DecoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): SnakeBeta()\n",
       "              (1): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (4): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): DecoderBlock(\n",
       "            (layers): Sequential(\n",
       "              (0): SnakeBeta()\n",
       "              (1): ConvTranspose1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "              (2): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (3): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "              (4): ResidualUnit(\n",
       "                (layers): Sequential(\n",
       "                  (0): SnakeBeta()\n",
       "                  (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(27,), dilation=(9,))\n",
       "                  (2): SnakeBeta()\n",
       "                  (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): SnakeBeta()\n",
       "          (7): Conv1d(128, 2, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "          (8): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import torch\n",
    "#import json\n",
    "#from stable_audio_tools.models.diffusion import create_diffusion_cond_from_config\n",
    "\n",
    "# Load saved config\n",
    "#with open(\"/workspace/stable-audio-tools/saved/final_model_config.json\") as f:\n",
    "    #config = json.load(f)\n",
    "\n",
    "# Rebuild model from config\n",
    "#model = create_diffusion_cond_from_config(config)\n",
    "#ckpt = torch.load(\"/workspace/stable-audio-tools/saved/final_model.pt\", map_location=\"cuda\")\n",
    "#model.load_state_dict(ckpt[\"state_dict\"])\n",
    "#model.to(\"cuda\").eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96581be9-95dd-4649-b9ef-a13985fa854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/torch/hub\n"
     ]
    }
   ],
   "source": [
    "print(torch.hub.get_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33636b34-132f-4cd1-90b6-9dbcb43ef4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158142252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/stable-audio-tools/stable_audio_tools/models/conditioners.py:362: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.float16) and torch.set_grad_enabled(self.enable_grad):\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from stable_audio_tools.inference.generation import generate_diffusion_cond\n",
    "\n",
    "conditioning = [{\n",
    "    \"prompt\": \"Trap remix with evolving piano, gliding 808s, and hard-hitting drums\",\n",
    "    \"seconds_total\": 90.0\n",
    "}]\n",
    "\n",
    "negative_conditioning = [{\n",
    "    \"prompt\": \"no ambient drone, no static loop, no fade out\",\n",
    "    \"seconds_total\": 90.0\n",
    "}]\n",
    "\n",
    "\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "DURATION_SEC = sum(p[\"seconds_total\"] for p in conditioning)  # = 90\n",
    "SAMPLE_SIZE = int(SAMPLE_RATE * DURATION_SEC)  # = 3,969,000\n",
    "\n",
    "\n",
    "output = generate_diffusion_cond(\n",
    "    model=model.to(\"cuda\"),       # make 100% sure model is on GPU\n",
    "    steps=2048,\n",
    "    cfg_scale=6.5,\n",
    "    conditioning=conditioning,\n",
    "    negative_conditioning=negative_conditioning,\n",
    "    sample_size=SAMPLE_SIZE,       # 9 seconds\n",
    "    device=\"cuda\"                 # force everything onto GPU\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328b845-8617-47be-9291-7d975c8af7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from einops import rearrange\n",
    "\n",
    "# Rearrange: [B, C, T] -> [C, T] for saving\n",
    "waveform = rearrange(output, \"b c n -> c (b n)\")\n",
    "\n",
    "# Peak normalize and convert to 16-bit PCM\n",
    "waveform = waveform.to(torch.float32).div(torch.max(torch.abs(waveform))).mul(32767).clamp(-32768, 32767).to(torch.int16).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278da9b7-c3d2-49f8-8a27-9fa49d5e5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\"remix_output_prompt_1536_steps.wav\", waveform, sample_rate=44100)\n",
    "print(\"✅ Saved to remix_output_prompt_1536_steps.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
